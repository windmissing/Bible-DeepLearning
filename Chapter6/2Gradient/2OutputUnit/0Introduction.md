代价函数的选择与输出单元的选择紧密相关。
大多数时候，我们简单地使用数据分布和模型分布间的交叉熵。
选择如何表示输出决定了交叉熵函数的形式。

> **[success]**  
经常使用数据分布与模型分布的交叉熵作为代价函数。  
因此，模型分布的输出层决定了交叉熵的形式，也决定了代价函数的形式。  

任何可用作输出的神经网络单元，也可以被用作隐藏单元。
这里，我们着重讨论将这些单元用作模型输出时的情况，不过原则上它们也可以在内部使用。
我们将在\sec?中重温这些单元，并且给出当它们被用作隐藏单元时一些额外的细节。

在本节中，我们假设前馈网络提供了一组定义为$h=f(x;\theta)$的隐藏特征。
输出层的作用是随后对这些特征进行一些额外的变换来完成整个网络必须完成的任务。

> **[success]**  
6.2节讨论的这些单元可以用于输出层神经元，也可以用作中间层神经元。但这里只讨论它们作为输出层神经元时的情况。以及它们对应的代码函数  
*神经元=单元，不同的书上用的术语不同。*

有时，我们使用一个更简单的方法，不是预测$y$的完整概率分布，而是仅仅预测在给定$x$的条件下$y$的某种统计量。
某些专门的损失函数允许我们来训练这些估计量的预测器。  